{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: NLP and the Pipeline\n",
    "\n",
    "* DS 6001\n",
    "* Raf Alvarado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai-gvPnADykO",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Overview\n",
    "\n",
    "We import a collection of texts and convert to F2. Then we annotate the collection to create an F3-level model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "epub_dir = 'epubs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAzRbscg1ziu"
   },
   "source": [
    "## Import NLTK and download resources\n",
    "\n",
    "If you need to install NLTK, see the [instructions here](https://www.nltk.org/install.html). You can also install this with Anaconda, like so:\n",
    "\n",
    "`conda install nltk`\n",
    "\n",
    "Once you have installed NLTK, you will need to download resources, which will happen when you run the following cell. If the interactive window opens, you may need to set your NLTK Data Directory, as described in the [instructions here](https://www.nltk.org/data.html). To set the directory, click on the File menu and select Change Download Directory. For central installation, set this to `C:\\nltk_data` (Windows),`/usr/local/share/nltk_data` (Mac), or `/usr/share/nltk_data` (Unix). \n",
    "\n",
    "> If you did not install the data to one of the above central locations, you will need to set the NLTK_DATA environment variable to specify the location of the data. (On a Windows machine, right click on “My Computer” then select Properties > Advanced > Environment Variables > User Variables > New...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "Q4Id4bNP5t4p",
    "outputId": "1be778b1-a6a6-45e5-8773-010e83904be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /Users/rca2t/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire\n",
    "\n",
    "We download the novels of Jane Austen and Herman Melville from Project Gutenberg. I actually used a utility I created called PGTK:\n",
    "\n",
    "* https://github.com/ontoligent-design/pgtk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect\n",
    "\n",
    "Since Project Gutenberg texts vary widely in their markup, we define our chunking patterns by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "chap_pats = {\n",
    "    158: {\n",
    "        'start_line': 37,\n",
    "        'end_line': 16261,\n",
    "        'volume': re.compile('^\\s*VOLUME\\s+{}\\s*$'.format(roman)),\n",
    "        'chapter': re.compile('^\\s*CHAPTER\\s+{}\\s*$'.format(roman))\n",
    "    },\n",
    "    946: {\n",
    "        'start_line': 38,\n",
    "        'end_line': 2556,\n",
    "        'chapter': re.compile(\"^\\s*{}\\s*$\".format(roman))\n",
    "    },\n",
    "    1212: {\n",
    "        'start_line': 77,\n",
    "        'end_line': 3432,\n",
    "        'chapter': re.compile(\"^\\s*LETTER .* to .*$\")\n",
    "    },\n",
    "    141: {\\\n",
    "        'start_line': 40,\n",
    "        'end_line': 15376,\n",
    "        'chapter': re.compile(\"^CHAPTER\\s+{}$\".format(roman))\n",
    "    },\n",
    "    121: {\n",
    "        'start_line': 57,\n",
    "        'end_line': 7874,\n",
    "        'chapter': re.compile(\"^CHAPTER\\s+\\d+$\")\n",
    "    },\n",
    "    105: {\n",
    "        'start_line': 48,\n",
    "        'end_line': 8360,\n",
    "        'chapter': re.compile(\"^Chapter\\s+\\d+$\")\n",
    "    },\n",
    "    1342: {\n",
    "        'start_line': 37,\n",
    "        'end_line': 13061,\n",
    "        'chapter': re.compile(\"^Chapter\\s+\\d+$\")\n",
    "    },\n",
    "    161: {\n",
    "        'start_line': 43,\n",
    "        'end_line': 12654,\n",
    "        'chapter': re.compile(\"^CHAPTER\\s+\\d+$\")          \n",
    "    },\n",
    "    15422: {\n",
    "        'start_line': 193,\n",
    "        'end_line': 7501,\n",
    "        'chapter': re.compile(\"^\\s*CHAPTER\\s+{}\\.\".format(roman))\n",
    "    },\n",
    "    13720: {\n",
    "        'start_line': 187,\n",
    "        'end_line': 11470,\n",
    "        'chapter': re.compile(\"^\\s*CHAPTER\\s+{}\\s*$\".format(roman))\n",
    "    },\n",
    "    13721: {\n",
    "        'start_line': 164,\n",
    "        'end_line': 13135,\n",
    "        'chapter': re.compile(\"^\\s*CHAPTER\\s+{}\\s*$\".format(roman))\n",
    "    },\n",
    "    2701: {\n",
    "        'start_line': 52,\n",
    "        'end_line': 21743,\n",
    "        'chapter': re.compile(\"^(ETYMOLOGY|EXTRACTS|CHAPTER)\")\n",
    "    },\n",
    "    4045: {\n",
    "        'start_line': 138,\n",
    "        'end_line': 11655,\n",
    "        'volume': re.compile(\"^\\s*PART\\s+{}\\s*$\".format(roman)),\n",
    "        'chapter': re.compile(\"^\\s*CHAPTER\\s+{}\\.\\s*$\".format(roman))\n",
    "    },\n",
    "    34970: {\n",
    "        'start_line': 234,\n",
    "        'end_line': 16267,\n",
    "        'volume': re.compile(\"^\\s*BOOK\\s+{}\\.\\s*$\".format(roman)),\n",
    "        'chapter': re.compile(\"^\\s*{}\\.\\s*$\".format(roman))\n",
    "    },\n",
    "    8118: {\n",
    "        'start_line': 142,\n",
    "        'end_line': 12300,\n",
    "        'chapter': re.compile(\"^\\s*{}\\. .*$\".format(roman))\n",
    "    },\n",
    "    53861: {\n",
    "        'start_line': 129,\n",
    "        'end_line': 6904,\n",
    "        'chapter': re.compile('^\\s*{}\\s*$'.format(caps))\n",
    "    },\n",
    "    21816: {\n",
    "        'start_line': 309,\n",
    "        'end_line': 11023,\n",
    "        'chapter': re.compile('^CHAPTER\\s+{}\\.?$'.format(roman))\n",
    "    },\n",
    "    15859: {\n",
    "        'start_line': 77,\n",
    "        'end_line': 8619,\n",
    "        'chapter': re.compile('^\\s*{}\\s*$'.format(caps))\n",
    "    },\n",
    "    1900: {\n",
    "        'start_line': 43,\n",
    "        'end_line': 11216,\n",
    "        'chapter': re.compile(\"^CHAPTER\\s+\\w+\\s*$\")\n",
    "    },\n",
    "    10712: {\n",
    "        'start_line': 205,\n",
    "        'end_line': 15487,\n",
    "        'chapter': re.compile(\"^CHAPTER\\s+{}\\.\\s*$\".format(roman))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register and Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_epubs(epub_list, chap_pats, OHCO=OHCO):\n",
    "    \n",
    "    my_lib = []\n",
    "    my_doc = []\n",
    "\n",
    "    for epub_file in epub_list:\n",
    "        \n",
    "        # Get PG ID from filename\n",
    "        book_id = int(epub_file.split('-')[-1].split('.')[0].replace('pg',''))\n",
    "        print(\"BOOK ID\", book_id)\n",
    "        \n",
    "        # Import file as lines\n",
    "        lines = open(epub_file, 'r', encoding='utf-8-sig').readlines()\n",
    "        df = pd.DataFrame(lines, columns=['line_str'])\n",
    "        df.index.name = 'line_num'\n",
    "        df.line_str = df.line_str.str.strip()\n",
    "        df['book_id'] = book_id\n",
    "        \n",
    "        # FIX CHARACTERS TO IMPROVE TOKENIZATION\n",
    "        df.line_str = df.line_str.str.replace('—', ' — ')\n",
    "        df.line_str = df.line_str.str.replace('-', ' - ')\n",
    "        \n",
    "        # Get book title and put into LIB table -- note problems, though\n",
    "        book_title = re.sub(r\"The Project Gutenberg eBook( of|,) \", \"\", df.loc[0].line_str, flags=re.IGNORECASE)\n",
    "        book_title = re.sub(r\"Project Gutenberg's \", \"\", book_title, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Remove cruft\n",
    "        a = chap_pats[book_id]['start_line'] - 1\n",
    "        b = chap_pats[book_id]['end_line'] + 1\n",
    "        df = df.iloc[a:b]\n",
    "        \n",
    "        # Chunk by chapter\n",
    "        chap_lines = df.line_str.str.match(chap_pats[book_id]['chapter'])\n",
    "        chap_nums = [i+1 for i in range(df.loc[chap_lines].shape[0])]\n",
    "        df.loc[chap_lines, 'chap_num'] = chap_nums\n",
    "        df.chap_num = df.chap_num.ffill()\n",
    "\n",
    "        # Clean up\n",
    "        df = df[~df.chap_num.isna()] # Remove chapter heading lines\n",
    "        df = df.loc[~chap_lines] # Remove everything before Chapter 1\n",
    "        df['chap_num'] = df['chap_num'].astype('int')\n",
    "        \n",
    "        # Group -- Note that we exclude the book level in the OHCO at this point\n",
    "        df = df.groupby(OHCO[1:2]).line_str.apply(lambda x: '\\n'.join(x)).to_frame() # Make big string\n",
    "        \n",
    "        # Split into paragrpahs\n",
    "        df = df['line_str'].str.split(r'\\n\\n+', expand=True).stack().to_frame().rename(columns={0:'para_str'})\n",
    "        df.index.names = OHCO[1:3] # MAY NOT BE NECESSARY UNTIL THE END\n",
    "        df['para_str'] = df['para_str'].str.replace(r'\\n', ' ').str.strip()\n",
    "        df = df[~df['para_str'].str.match(r'^\\s*$')] # Remove empty paragraphs\n",
    "        \n",
    "        # Set index\n",
    "        df['book_id'] = book_id\n",
    "        df = df.reset_index().set_index(OHCO[:3])\n",
    "\n",
    "        # Register\n",
    "        my_lib.append((book_id, book_title, epub_file))\n",
    "        my_doc.append(df)\n",
    "\n",
    "    docs = pd.concat(my_doc)\n",
    "    library = pd.DataFrame(my_lib, columns=['book_id', 'book_title', 'book_file']).set_index('book_id')\n",
    "    return library, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK ID 158\n",
      "BOOK ID 946\n",
      "BOOK ID 1212\n",
      "BOOK ID 141\n",
      "BOOK ID 121\n",
      "BOOK ID 105\n",
      "BOOK ID 1342\n",
      "BOOK ID 161\n",
      "BOOK ID 15422\n",
      "BOOK ID 13720\n",
      "BOOK ID 13721\n",
      "BOOK ID 2701\n",
      "BOOK ID 4045\n",
      "BOOK ID 34970\n",
      "BOOK ID 8118\n",
      "BOOK ID 53861\n",
      "BOOK ID 21816\n",
      "BOOK ID 15859\n",
      "BOOK ID 1900\n",
      "BOOK ID 10712\n"
     ]
    }
   ],
   "source": [
    "epubs = [epub for epub in sorted(glob(epub_dir+'/*.txt'))]\n",
    "LIB, DOC = acquire_epubs(epubs, chap_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <th>37</th>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Crawford gone, Sir Thomas's next object wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21816</th>\n",
       "      <th>18</th>\n",
       "      <th>2</th>\n",
       "      <td>\"But do you think it the fair thing to unmask ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13720</th>\n",
       "      <th>46</th>\n",
       "      <th>13</th>\n",
       "      <td>So away floated the Chamois, like a vagrant cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <th>17</th>\n",
       "      <th>54</th>\n",
       "      <td>\"Well said, old man,\" cried Babbalanja; \"for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <th>13</th>\n",
       "      <th>7</th>\n",
       "      <td>If there yet lurked any ice of indifference to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <th>43</th>\n",
       "      <th>14</th>\n",
       "      <td>\"Does that young lady know Mr. Darcy?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <th>76</th>\n",
       "      <th>116</th>\n",
       "      <td>BABBALANJA -  - Very funny, your Highness: -  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <th>42</th>\n",
       "      <th>15</th>\n",
       "      <td>After a moment's reflection, Mr. Crawford repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <th>16</th>\n",
       "      <th>30</th>\n",
       "      <td>Isabella shrugged her shoulders and smiled, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <td>A few months had seen the beginning and the en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    para_str\n",
       "book_id chap_num para_num                                                   \n",
       "141     37       0         Mr. Crawford gone, Sir Thomas's next object wa...\n",
       "21816   18       2         \"But do you think it the fair thing to unmask ...\n",
       "13720   46       13        So away floated the Chamois, like a vagrant cl...\n",
       "13721   17       54        \"Well said, old man,\" cried Babbalanja; \"for, ...\n",
       "2701    13       7         If there yet lurked any ice of indifference to...\n",
       "1342    43       14                   \"Does that young lady know Mr. Darcy?\"\n",
       "13721   76       116       BABBALANJA -  - Very funny, your Highness: -  ...\n",
       "141     42       15        After a moment's reflection, Mr. Crawford repl...\n",
       "121     16       30        Isabella shrugged her shoulders and smiled, th...\n",
       "105     4        6         A few months had seen the beginning and the en..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and Annotate\n",
    "\n",
    "We use NLTK this time. Note that this process takes some time, mainly because the NLTK functions are not optimized for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.para_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = tokenize(DOC, ws=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">158</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Emma, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Emma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Woodhouse,, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Woodhouse,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(handsome,, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>handsome,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(clever,, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>clever,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(and, CC)</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      pos_tuple  pos  \\\n",
       "book_id chap_num para_num sent_num token_num                           \n",
       "158     1        1        0        0                (Emma, NNP)  NNP   \n",
       "                                   1          (Woodhouse,, NNP)  NNP   \n",
       "                                   2            (handsome,, NN)   NN   \n",
       "                                   3              (clever,, NN)   NN   \n",
       "                                   4                  (and, CC)   CC   \n",
       "\n",
       "                                               token_str  \n",
       "book_id chap_num para_num sent_num token_num              \n",
       "158     1        1        0        0                Emma  \n",
       "                                   1          Woodhouse,  \n",
       "                                   2           handsome,  \n",
       "                                   3             clever,  \n",
       "                                   4                 and  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">158</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>8</th>\n",
       "      <td>(comfortable, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(happy, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(best, JJS)</td>\n",
       "      <td>JJS</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(twenty, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>twenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(little, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>3</th>\n",
       "      <td>(youngest, JJS)</td>\n",
       "      <td>JJS</td>\n",
       "      <td>youngest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(affectionate,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>affectionate,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(early, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>11</th>\n",
       "      <td>(more, JJR)</td>\n",
       "      <td>JJR</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(indistinct, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>indistinct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(excellent, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(little, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(short, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Sixteen, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Sixteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(friend,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>friend,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>9</th>\n",
       "      <td>(nominal, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(attached,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>attached,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>(real, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(evils,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>evils,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(much, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(own, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(little, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(many, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>5</th>\n",
       "      <td>(present, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(unperceived,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>unperceived,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>5</th>\n",
       "      <td>(gentle, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>gentle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(disagreeable, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>disagreeable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>16</th>\n",
       "      <td>(mournful, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>mournful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>5</th>\n",
       "      <td>(bride, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>bride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(third, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">10712</th>\n",
       "      <th rowspan=\"30\" valign=\"top\">92</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">17</th>\n",
       "      <th>0</th>\n",
       "      <th>15</th>\n",
       "      <td>(unhappy,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>unhappy,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>6</th>\n",
       "      <td>(gallant, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>gallant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(top, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">18</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>10</th>\n",
       "      <td>(main, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(own, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>21</th>\n",
       "      <td>(unlegalised, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>unlegalised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">19</th>\n",
       "      <th>0</th>\n",
       "      <th>27</th>\n",
       "      <td>(little, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>17</th>\n",
       "      <td>(clean, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(oft, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>oft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(painted, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>painted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(vast, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>vast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">20</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>8</th>\n",
       "      <td>(up,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>up,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(more, JJR)</td>\n",
       "      <td>JJR</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(tow, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>tow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(own, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>0</th>\n",
       "      <th>15</th>\n",
       "      <td>(subterranean, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>subterranean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">22</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <td>(many, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <td>(full, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>25</th>\n",
       "      <td>(indefinite, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>indefinite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <td>(worst, JJS)</td>\n",
       "      <td>JJS</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>2</th>\n",
       "      <td>(last, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(another;, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>another;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(own, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th>5</th>\n",
       "      <td>(us,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>us,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(murderous, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>murderous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(bloody, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>bloody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>9</th>\n",
       "      <td>(long, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(unredressed,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>unredressed,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">23</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>2</th>\n",
       "      <td>(us,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>us,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(surround,, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>surround,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166432 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        pos_tuple  pos  \\\n",
       "book_id chap_num para_num sent_num token_num                             \n",
       "158     1        1        0        8            (comfortable, JJ)   JJ   \n",
       "                                   11                 (happy, JJ)   JJ   \n",
       "                                   19                 (best, JJS)  JJS   \n",
       "                                   27                (twenty, JJ)   JJ   \n",
       "                                   36                (little, JJ)   JJ   \n",
       "                 2        0        3              (youngest, JJS)  JJS   \n",
       "                                   11         (affectionate,, JJ)   JJ   \n",
       "                                   30                 (early, JJ)   JJ   \n",
       "                          1        11                 (more, JJR)  JJR   \n",
       "                                   14            (indistinct, JJ)   JJ   \n",
       "                                   27             (excellent, JJ)   JJ   \n",
       "                                   34                (little, JJ)   JJ   \n",
       "                                   35                 (short, JJ)   JJ   \n",
       "                 3        0        0                (Sixteen, JJ)   JJ   \n",
       "                                   16               (friend,, JJ)   JJ   \n",
       "                          2        9                (nominal, JJ)   JJ   \n",
       "                                   47             (attached,, JJ)   JJ   \n",
       "                 4        0        1                   (real, JJ)   JJ   \n",
       "                                   2                 (evils,, JJ)   JJ   \n",
       "                                   14                  (much, JJ)   JJ   \n",
       "                                   16                   (own, JJ)   JJ   \n",
       "                                   24                (little, JJ)   JJ   \n",
       "                                   38                  (many, JJ)   JJ   \n",
       "                          1        5                (present, JJ)   JJ   \n",
       "                                   7           (unperceived,, JJ)   JJ   \n",
       "                 5        0        5                 (gentle, JJ)   JJ   \n",
       "                                   18          (disagreeable, JJ)   JJ   \n",
       "                          3        16              (mournful, JJ)   JJ   \n",
       "                          4        5                  (bride, JJ)   JJ   \n",
       "                                   23                 (third, JJ)   JJ   \n",
       "...                                                           ...  ...   \n",
       "10712   92       17       0        15              (unhappy,, JJ)   JJ   \n",
       "                          2        6                (gallant, JJ)   JJ   \n",
       "                                   11                   (top, JJ)   JJ   \n",
       "                 18       0        10                  (main, JJ)   JJ   \n",
       "                                   34                   (own, JJ)   JJ   \n",
       "                          1        21           (unlegalised, JJ)   JJ   \n",
       "                 19       0        27                (little, JJ)   JJ   \n",
       "                          1        17                 (clean, JJ)   JJ   \n",
       "                                   22                   (oft, JJ)   JJ   \n",
       "                                   24               (painted, JJ)   JJ   \n",
       "                                   32                  (vast, JJ)   JJ   \n",
       "                 20       0        8                    (up,, JJ)   JJ   \n",
       "                                   21                 (more, JJR)  JJR   \n",
       "                                   35                   (tow, JJ)   JJ   \n",
       "                                   40                   (own, JJ)   JJ   \n",
       "                 21       0        15          (subterranean, JJ)   JJ   \n",
       "                 22       1        4                   (many, JJ)   JJ   \n",
       "                          2        5                   (full, JJ)   JJ   \n",
       "                          3        25            (indefinite, JJ)   JJ   \n",
       "                          4        2                 (worst, JJS)  JJS   \n",
       "                          5        2                   (last, JJ)   JJ   \n",
       "                                   8               (another;, JJ)   JJ   \n",
       "                                   15                   (own, JJ)   JJ   \n",
       "                          6        5                    (us,, JJ)   JJ   \n",
       "                                   11             (murderous, JJ)   JJ   \n",
       "                                   19                (bloody, JJ)   JJ   \n",
       "                          7        9                   (long, JJ)   JJ   \n",
       "                                   17          (unredressed,, JJ)   JJ   \n",
       "                 23       0        2                    (us,, JJ)   JJ   \n",
       "                                   4              (surround,, JJ)   JJ   \n",
       "\n",
       "                                                  token_str  \n",
       "book_id chap_num para_num sent_num token_num                 \n",
       "158     1        1        0        8            comfortable  \n",
       "                                   11                 happy  \n",
       "                                   19                  best  \n",
       "                                   27                twenty  \n",
       "                                   36                little  \n",
       "                 2        0        3               youngest  \n",
       "                                   11         affectionate,  \n",
       "                                   30                 early  \n",
       "                          1        11                  more  \n",
       "                                   14            indistinct  \n",
       "                                   27             excellent  \n",
       "                                   34                little  \n",
       "                                   35                 short  \n",
       "                 3        0        0                Sixteen  \n",
       "                                   16               friend,  \n",
       "                          2        9                nominal  \n",
       "                                   47             attached,  \n",
       "                 4        0        1                   real  \n",
       "                                   2                 evils,  \n",
       "                                   14                  much  \n",
       "                                   16                   own  \n",
       "                                   24                little  \n",
       "                                   38                  many  \n",
       "                          1        5                present  \n",
       "                                   7           unperceived,  \n",
       "                 5        0        5                 gentle  \n",
       "                                   18          disagreeable  \n",
       "                          3        16              mournful  \n",
       "                          4        5                  bride  \n",
       "                                   23                 third  \n",
       "...                                                     ...  \n",
       "10712   92       17       0        15              unhappy,  \n",
       "                          2        6                gallant  \n",
       "                                   11                   top  \n",
       "                 18       0        10                  main  \n",
       "                                   34                   own  \n",
       "                          1        21           unlegalised  \n",
       "                 19       0        27                little  \n",
       "                          1        17                 clean  \n",
       "                                   22                   oft  \n",
       "                                   24               painted  \n",
       "                                   32                  vast  \n",
       "                 20       0        8                    up,  \n",
       "                                   21                  more  \n",
       "                                   35                   tow  \n",
       "                                   40                   own  \n",
       "                 21       0        15          subterranean  \n",
       "                 22       1        4                   many  \n",
       "                          2        5                   full  \n",
       "                          3        25            indefinite  \n",
       "                          4        2                  worst  \n",
       "                          5        2                   last  \n",
       "                                   8               another;  \n",
       "                                   15                   own  \n",
       "                          6        5                    us,  \n",
       "                                   11             murderous  \n",
       "                                   19                bloody  \n",
       "                          7        9                   long  \n",
       "                                   17          unredressed,  \n",
       "                 23       0        2                    us,  \n",
       "                                   4              surround,  \n",
       "\n",
       "[166432 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN[TOKEN.pos.str.match('^JJ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Reduce\n",
    "\n",
    "Extract a vocabulary from the TOKEN table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TOKEN.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "3iYsuby6FYYR",
    "outputId": "b29dd1cd-a82a-44be-e21c-aa9b7e1e4933"
   },
   "outputs": [],
   "source": [
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "3iYsuby6FYYR",
    "outputId": "b29dd1cd-a82a-44be-e21c-aa9b7e1e4933"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>50493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10800</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10th</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>118952</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11th</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>125000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12th</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1399</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13th</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>144000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1492</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14th</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>zigzags</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>zimmermann</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>zion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>zmiglandi</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40455</th>\n",
       "      <td>znobbi</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40456</th>\n",
       "      <td>znobbis</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40457</th>\n",
       "      <td>znorto</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40458</th>\n",
       "      <td>zodiac</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40459</th>\n",
       "      <td>zodiacs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40460</th>\n",
       "      <td>zogranda</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40461</th>\n",
       "      <td>zone</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40462</th>\n",
       "      <td>zoned</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40463</th>\n",
       "      <td>zones</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40464</th>\n",
       "      <td>zono</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40465</th>\n",
       "      <td>zonoree</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40466</th>\n",
       "      <td>zoological</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40467</th>\n",
       "      <td>zoology</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40468</th>\n",
       "      <td>zooperbi</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40469</th>\n",
       "      <td>zoophytes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40470</th>\n",
       "      <td>zophar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40471</th>\n",
       "      <td>zoroaster</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40472</th>\n",
       "      <td>zozo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40473</th>\n",
       "      <td>zuma</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40474</th>\n",
       "      <td>zur</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40475</th>\n",
       "      <td>à</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40476</th>\n",
       "      <td>æneas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>æniad</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40478</th>\n",
       "      <td>æson</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40479</th>\n",
       "      <td>æsops</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40480</th>\n",
       "      <td>ł20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40481 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           term_str      n  num\n",
       "term_id                        \n",
       "0                    50493    0\n",
       "1                 0      2    1\n",
       "2                 1     18    1\n",
       "3                10      6    1\n",
       "4               100      2    1\n",
       "5              1000      2    1\n",
       "6             10000      3    1\n",
       "7           1000000      1    1\n",
       "8          10000000      1    1\n",
       "9             10440      1    1\n",
       "10            10800      2    1\n",
       "11             10th      2    1\n",
       "12         11000000      1    1\n",
       "13           118952      1    1\n",
       "14             11th      2    1\n",
       "15               12      5    1\n",
       "16           120000      1    1\n",
       "17           125000      1    1\n",
       "18             12th      1    1\n",
       "19               13      1    1\n",
       "20            13000      1    1\n",
       "21              139      2    1\n",
       "22             1399      1    1\n",
       "23             13th      3    1\n",
       "24              140      1    1\n",
       "25           144000      1    1\n",
       "26             1492      2    1\n",
       "27             14th      3    1\n",
       "28               15      2    1\n",
       "29              150      1    1\n",
       "...             ...    ...  ...\n",
       "40451       zigzags      2    0\n",
       "40452    zimmermann      3    0\n",
       "40453          zion      1    0\n",
       "40454     zmiglandi      2    0\n",
       "40455        znobbi      3    0\n",
       "40456       znobbis      1    0\n",
       "40457        znorto      1    0\n",
       "40458        zodiac     13    0\n",
       "40459       zodiacs      1    0\n",
       "40460      zogranda      1    0\n",
       "40461          zone     20    0\n",
       "40462         zoned      7    0\n",
       "40463         zones     11    0\n",
       "40464          zono      3    0\n",
       "40465       zonoree      3    0\n",
       "40466    zoological      5    0\n",
       "40467       zoology      4    0\n",
       "40468      zooperbi      2    0\n",
       "40469     zoophytes      2    0\n",
       "40470        zophar      1    0\n",
       "40471     zoroaster      2    0\n",
       "40472          zozo      1    0\n",
       "40473          zuma      8    0\n",
       "40474           zur      2    0\n",
       "40475             à      5    0\n",
       "40476         æneas      1    0\n",
       "40477         æniad      1    0\n",
       "40478          æson      2    0\n",
       "40479         æsops      1    0\n",
       "40480        ł20000      1    0\n",
       "\n",
       "[40481 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDSH9L2TXGzH",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Annotate (VOCAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "US7EfWK_06FS"
   },
   "source": [
    "## Add Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDCfFuN80_rX"
   },
   "source": [
    "We use NLTK's built in stopword list for English. Note that we can add and subtract from this list, or just create our own list and keep it in our data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RG-5qYDR1YC2"
   },
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1925
    },
    "colab_type": "code",
    "id": "8vtGY9V82scz",
    "outputId": "e7ef30c7-3a05-4acf-e2cc-9154f589bd91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ain</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>won't</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nor</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>while</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dummy\n",
       "term_str       \n",
       "where         1\n",
       "not           1\n",
       "it            1\n",
       "up            1\n",
       "on            1\n",
       "them          1\n",
       "ain           1\n",
       "won't         1\n",
       "nor           1\n",
       "while         1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVJUOP9l2AS7"
   },
   "outputs": [],
   "source": [
    "VOCAB['stop'] = VOCAB.term_str.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "QXcA9xyY4JF_",
    "outputId": "340d1dab-1901-4eeb-b9d8-a269eba90dea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11261</th>\n",
       "      <td>during</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11324</th>\n",
       "      <td>each</td>\n",
       "      <td>981</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16811</th>\n",
       "      <td>herself</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39745</th>\n",
       "      <td>whom</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35891</th>\n",
       "      <td>to</td>\n",
       "      <td>56220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39382</th>\n",
       "      <td>we</td>\n",
       "      <td>6291</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>as</td>\n",
       "      <td>17786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35380</th>\n",
       "      <td>than</td>\n",
       "      <td>3949</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24367</th>\n",
       "      <td>off</td>\n",
       "      <td>1675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24875</th>\n",
       "      <td>over</td>\n",
       "      <td>2885</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str      n  num  stop\n",
       "term_id                           \n",
       "11261     during    535    0     1\n",
       "11324       each    981    0     1\n",
       "16811    herself   1540    0     1\n",
       "39745       whom    860    0     1\n",
       "35891         to  56220    0     1\n",
       "39382         we   6291    0     1\n",
       "2121          as  17786    0     1\n",
       "35380       than   3949    0     1\n",
       "24367        off   1675    0     1\n",
       "24875       over   2885    0     1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bDSH9L2TXGzH"
   },
   "source": [
    "## Add Stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mE_YGklKXSYn"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "VOCAB['p_stem'] = VOCAB.term_str.apply(stemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "dY__Bq0yXqbj",
    "outputId": "eddcdafe-e378-4f7b-ac6b-1fc41ef64fbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>stop</th>\n",
       "      <th>p_stem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20587</th>\n",
       "      <td>legged</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23602</th>\n",
       "      <td>naughtiness</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>naughti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23103</th>\n",
       "      <td>morose</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>moros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27337</th>\n",
       "      <td>prescriptive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>prescript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15833</th>\n",
       "      <td>grooms</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>groom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21501</th>\n",
       "      <td>magnetical</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>magnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>cadell</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cadel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>arbored</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>arbor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30447</th>\n",
       "      <td>sachem</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sachem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18078</th>\n",
       "      <td>incensing</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>incens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term_str   n  num  stop     p_stem\n",
       "term_id                                        \n",
       "20587          legged  33    0     0        leg\n",
       "23602     naughtiness   1    0     0    naughti\n",
       "23103          morose   5    0     0      moros\n",
       "27337    prescriptive   1    0     0  prescript\n",
       "15833          grooms   3    0     0      groom\n",
       "21501      magnetical   1    0     0     magnet\n",
       "5008           cadell   1    0     0      cadel\n",
       "1859          arbored   3    0     0      arbor\n",
       "30447          sachem   1    0     0     sachem\n",
       "18078       incensing   2    0     0     incens"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC.to_csv('DOC.csv')\n",
    "LIB.to_csv('LIB.csv')\n",
    "VOCAB.to_csv('VOCAB.csv')\n",
    "TOKEN.to_csv('TOKEN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "TOKEN = TOKEN.drop('pos_tuple', 1)\n",
    "\n",
    "with sqlite3.connect('mod4-corpus.db') as db:\n",
    "    DOC.to_sql('doc', db, index=True, if_exists='replace')\n",
    "    LIB.to_sql('lib', db, index=True, if_exists='replace')\n",
    "    VOCAB.to_sql('vocab', db, index=True, if_exists='replace')\n",
    "    TOKEN.to_sql('token', db, index=True, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Explore NER tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'pos_tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DS5001/lib/python3.5/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         raise AttributeError(\"%r object has no attribute %r\" %\n\u001b[0;32m--> 765\u001b[0;31m                              (type(self).__name__, attr))\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     @Substitution(klass='GroupBy',\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'pos_tuple'"
     ]
    }
   ],
   "source": [
    "%time NER = TOKEN.groupby(OHCO[:4]).pos_tuple.apply(lambda x: nltk.ne_chunk(x.tolist())).to_frame().rename(columns={'pos_tuple':'nltk_sentence'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ee86016ce180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'NER' is not defined"
     ]
    }
   ],
   "source": [
    "NER.iloc[8].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER.iloc[26].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfMtOiCYDylX",
    "toc-hr-collapsed": false
   },
   "source": [
    "# POS Tagset\n",
    "\n",
    "This a token-level feature -- not a vocab feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFoFrPTSN4s_"
   },
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_Annotations.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
